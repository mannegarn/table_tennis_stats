{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7aec68f-2be8-494a-b006-dd046f01e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from typing import Tuple, Optional\n",
    "from datetime import datetime\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "103e9b90-7b06-432e-bc39-ffae6f36877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- Configuration--------------------\n",
    "# Get current date for file naming.\n",
    "now_date = datetime.now()\n",
    "\n",
    "\n",
    "MASTER_EVENTS_DIR = \"../Data/Master/Events\"\n",
    "MASTER_EVENTS_SUFFIX = \"master_events.csv\"\n",
    "MASTER_EVENTS_REGEX = rf\"^\\d{{8}}{re.escape('_')}{re.escape(MASTER_EVENTS_SUFFIX)}$\"\n",
    "\n",
    "\n",
    "INTERMEDIATE_EVENTS_DIR= \"../Data/Processed/Events/Intermediate/\"\n",
    "INTERMEDIATE_EVENTS_SUFFIX = \"_intermediate_events.csv\"\n",
    "INTERMEDIATE_EVENTS_REGEX = rf\"^\\d{{8}}{re.escape(INTERMEDIATE_EVENTS_SUFFIX)}$\"\n",
    "\n",
    "\n",
    "# Manual made table sponsor information \n",
    "EVENTS_SPONSORS_DIR = \"../Data/Processed/Sponsors\"\n",
    "EVENTS_SPONSORS_SUFFIX = \"_event_sponsors.csv\"\n",
    "EVENTS_SPONSORS_REGEX = rf\"^\\d{{8}}{re.escape(EVENTS_SPONSORS_SUFFIX)}$\"\n",
    "\n",
    "\n",
    "#used to return dummy /placeholder Df if no existing data is found \n",
    "# currently just used to check if df is empty: can be used \n",
    "MINIMAL_EVENT_COLUMNS = [\"eventId\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31a97633-4e27-49dd-aec3-e0d6f68c72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_master_events(master_dir:str, master_regex) -> Tuple[pd.DataFrame,Optional[str]]:\n",
    "    \"\"\"\n",
    "    Parses specified directory for events files in format yyyy_mm_dd. \n",
    "    Attempts to read latest file in this format. \n",
    "\n",
    "    Args:\n",
    "        directory (str): The folder where the master files are stored (e.g., '../Data/Events/Intermediate').\n",
    "        filename_pattern (str): The pattern to match (e.g., '*_events_intermediate.csv').\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame,Optional]: returns DF with data if available or blank df if data unavailable\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(master_dir):\n",
    "        print (f\"‚ùå{master_dir} does not exist as a directory\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None    \n",
    "    \n",
    "    # Get csv files in \n",
    "    files = glob.glob(f\"{master_dir}/*.csv\")\n",
    "   \n",
    "\n",
    "    master_files = []\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ùå No existing *.csv files found in MASTER Events Directory: {master_dir} \")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None \n",
    "\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)    \n",
    "       \n",
    "        if re.match(master_regex,filename):\n",
    "            master_files.append(file)\n",
    "\n",
    "    if not master_files:\n",
    "        print(f\"‚ùå No existing MASTER files in format: {master_regex} in {master_dir}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None \n",
    "    master_files.sort()    \n",
    "    latest_master = master_files[-1]\n",
    "\n",
    "    try: \n",
    "        latest_master_df = pd.read_csv(latest_master)\n",
    "        print(f\"‚úÖ {len(latest_master_df)} events found in latest MASTER: {latest_master} \")\n",
    "        return latest_master_df, latest_master\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"‚ùå Error reading lastest MASTER, {latest_master}: {e}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2b2f78f-7de8-49c2-a2bb-237b58a37670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_intermediate_events(intermediate_dir:str, intermediate_regex) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parses specified directory for events files in format yyyy_mm_dd. \n",
    "    Attempts to read latest file in this format. \n",
    "\n",
    "    Args:\n",
    "        directory (str): The folder where the intermediate files are stored (e.g., '../Data/Events/Intermediate').\n",
    "        filename_pattern (str): The pattern to match (e.g., '*_events_intermediate.csv').\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: The DataFrame of the latest file, or None if no files are found or reading fails.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(intermediate_dir):\n",
    "        print (f\"‚ùå{intermediate_dir} does not exist as a directory\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None   \n",
    "    \n",
    "    # Get csv files in \n",
    "    files = glob.glob(f\"{intermediate_dir}/*.csv\")\n",
    "   \n",
    "\n",
    "    intermediate_files = []\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ùå No existing *.csv files found in INTERMEDIATE Events Directory: {intermediate_dir} \")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None\n",
    "\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)\n",
    "       \n",
    "        if re.match(intermediate_regex,filename):\n",
    "           intermediate_files.append(file)\n",
    "\n",
    "    if not intermediate_files:\n",
    "        print(f\"‚ùå No existing INTERMEDIATE files in format: {intermediate_regex} in {intermediate_dir}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS),None \n",
    "    intermediate_files.sort()    \n",
    "    latest_intermediate = intermediate_files[-1]\n",
    "\n",
    "    try: \n",
    "        latest_intermediate_df = pd.read_csv(latest_intermediate)\n",
    "        print(f\"‚úÖ {len(latest_intermediate_df)} events found in latest INTERMEDIATE: {latest_intermediate} \")\n",
    "        return latest_intermediate_df, latest_intermediate\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"‚ùå Error reading lastest INTERMEDIATE, {latest_intermediate}: {e}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44f11409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_event_sponsor(event_sponsor_dir:str, event_sponsor_regex) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parses specified directory for events files in format yyyy_mm_dd. \n",
    "    Attempts to read latest file in this format. \n",
    "\n",
    "    Args:\n",
    "        directory (str): The folder where the event_sponsor files are stored (e.g., '../Data/Events/Intermediate').\n",
    "        filename_pattern (str): The pattern to match (e.g., '*_event_sponsor.csv').\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: The DataFrame of the latest file, or None if no files are found or reading fails.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(event_sponsor_dir):\n",
    "        print (f\"‚ùå{event_sponsor_dir} does not exist as a directory\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS)   \n",
    "    \n",
    "    # Get csv files in \n",
    "    files = glob.glob(f\"{event_sponsor_dir}/*.csv\")\n",
    "   \n",
    "\n",
    "    event_sponsor_files = []\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ùå No existing *.csv files found in EVENTS_SPONSORS  Directory: {event_sponsor_dir} \")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None  \n",
    "\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)\n",
    "       \n",
    "        if re.match(event_sponsor_regex,filename):\n",
    "           event_sponsor_files.append(file)\n",
    "\n",
    "    if not event_sponsor_files:\n",
    "        print(f\"‚ùå No existing EVENTS_SPONSORS files in format: {event_sponsor_regex} in {event_sponsor_dir}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS)   \n",
    "    event_sponsor_files.sort()    \n",
    "    latest_event_sponsor = event_sponsor_files[-1]\n",
    "\n",
    "    try: \n",
    "        latest_event_sponsor_df = pd.read_csv(latest_event_sponsor)\n",
    "        print(f\"‚úÖ {len(latest_event_sponsor_df)} events found in latest EVENTS_SPONSORS: {latest_event_sponsor} \")\n",
    "        return latest_event_sponsor_df, latest_event_sponsor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"‚ùå Error reading lastest EVENTS_SPONSORS, {file}: {e}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 188 events found in latest MASTER: ../Data/Master/Events/20251119_master_events.csv \n",
      "‚úÖ 188 events found in latest INTERMEDIATE: ../Data/Processed/Events/Intermediate/20251119_intermediate_events.csv \n",
      "‚úÖ 188 events found in latest EVENTS_SPONSORS: ../Data/Processed/Sponsors/20251119_event_sponsors.csv \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['EventName'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m     latest_sponsors_date_str = os.path.basename(latest_sponsors_file).split(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m     21\u001b[39m     latest_sponsors_date = pd.to_datetime(latest_sponsors_date_str)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mlatest_sponsors_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEventName\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOK\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m     sys.exit(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/table_tennis_stats/.venv/lib/python3.13/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/table_tennis_stats/.venv/lib/python3.13/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/table_tennis_stats/.venv/lib/python3.13/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/table_tennis_stats/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['EventName'] not found in axis\""
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    latest_master_df, latest_master_file = get_latest_master_events(MASTER_EVENTS_DIR, MASTER_EVENTS_REGEX)\n",
    "    if (not latest_master_df.empty) & bool(latest_master_file):   \n",
    "        latest_master_date_str = os.path.basename(latest_master_file).split(\"_\")[0]\n",
    "        latest_master_date = pd.to_datetime(latest_master_date_str)\n",
    "\n",
    "    \n",
    "    latest_intermediate_df, latest_intermediate_file = get_latest_intermediate_events(INTERMEDIATE_EVENTS_DIR, INTERMEDIATE_EVENTS_REGEX)\n",
    "    if (not latest_intermediate_df.empty) and bool(latest_intermediate_file):\n",
    "        latest_intermediate_date_str = os.path.basename(latest_intermediate_file).split(\"_\")[0]\n",
    "        latest_intermediate_date = pd.to_datetime(latest_intermediate_date_str)\n",
    "    else:\n",
    "        sys.exit(1)\n",
    "        print(\"‚ùå No intermdiate nor master events file found \")\n",
    "        \n",
    "    latest_sponsors_df, latest_sponsors_file = get_latest_event_sponsor(EVENTS_SPONSORS_DIR,EVENTS_SPONSORS_REGEX)\n",
    "    if (not latest_sponsors_df.empty) and bool(latest_sponsors_file):\n",
    "        latest_sponsors_date_str = os.path.basename(latest_sponsors_file).split(\"_\")[0]\n",
    "        latest_sponsors_date = pd.to_datetime(latest_sponsors_date_str)\n",
    "        latest_sponsors_df.drop(columns = [\"EventName\"],errors=\"OK\", inplace=True)\n",
    "    else:\n",
    "        sys.exit(1)\n",
    "        print(\"‚ùå No Sponsors Data file found \")\n",
    "    \n",
    "    if (not latest_master_df.empty):\n",
    "        if (latest_master_date > latest_intermediate_date) & (latest_master_date > latest_sponsors_date):\n",
    "            print(f\"Latest Master is already updated\")\n",
    "           \n",
    "        else:\n",
    "            # latest_master_df.drop(columns=[\"BallSponsor\",\"TableSponsor\"])\n",
    "            latest_intermediate_df = latest_intermediate_df.drop(columns=[\"BallSponsor\",\"TableSponsor\"])\n",
    "            \n",
    "            print(\"--- üü¢ Enriching Intermdiate file with sponsors üü¢---\")\n",
    "            enriched_df = enriched_df = pd.merge(how=\"left\",\n",
    "                left=latest_intermediate_df,\n",
    "                right=latest_sponsors_df,\n",
    "                on=\"eventId\")\n",
    "                \n",
    "            try:     \n",
    "                now_date = datetime.now()\n",
    "                date_string = now_date.strftime(\"%Y%m%d\")\n",
    "                new_master_name = f\"{date_string}_{MASTER_EVENTS_SUFFIX}\"\n",
    "                new_master_path = os.path.join(MASTER_EVENTS_DIR,new_master_name)\n",
    "                \n",
    "                enriched_df = enriched_df.sort_values(by=\"StartDate\", ascending= True)\n",
    "                enriched_df.to_csv(new_master_path, index=False)\n",
    "                print(f\"--- üü¢ Successfully saved {len(enriched_df)} total events to {new_master_path} üü¢---\")\n",
    "            except Exception as e:\n",
    "                print(f\"--- ‚ùå FAILED to  save new Mater Events File  {e} ---\")\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2163889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eventId', 'BallSponsor', 'TableSponsor', 'EventName'], dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_sponsors_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0473da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table_tennis_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
