{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e7aec68f-2be8-494a-b006-dd046f01e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import requests\n",
    "from typing import List, Union,  Optional\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "879bb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- Configuration--------------------\n",
    "\n",
    "\n",
    "INTERMEDIATE_EVENTS_DIR= \"../Data/Processed/Events/Intermediate/\"\n",
    "INTERMEDIATE_EVENTS_SUFFIX = \"_intermediate_events.csv\"\n",
    "INTERMEDIATE_EVENTS_REGEX = rf\"^\\d{{8}}{re.escape(INTERMEDIATE_EVENTS_SUFFIX)}$\"\n",
    "\n",
    "\n",
    "# Manual made table sponsor information \n",
    "EVENTS_SPONSORS_DIR = \"../Data/Processed/Sponsors\"\n",
    "EVENTS_SPONSORS_SUFFIX = \"_event_sponsors.csv\"\n",
    "EVENTS_SPONSORS_REGEX = rf\"^\\d{{8}}{re.escape(EVENTS_SPONSORS_SUFFIX)}$\"\n",
    "\n",
    "\n",
    "#used to return dummy /placeholder Df if no existing data is found \n",
    "# currently just used to check if df is empty: can be used \n",
    "MINIMAL_EVENT_COLUMNS = [\"eventId\"]\n",
    "\n",
    "LINKS_MAP_FILE = \"../Data/Processed/Sponsors/sponsor_links_map.json\"\n",
    "LOGOS_MAP_FILE = \"../Data/Processed/Sponsors/sponsor_logos_map.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f962cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_event_sponsor(event_sponsor_dir:str, event_sponsor_regex) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parses specified directory for events files in format yyyy_mm_dd. \n",
    "    Attempts to read latest file in this format. \n",
    "\n",
    "    Args:\n",
    "        directory (str): The folder where the event_sponsor files are stored (e.g., '../Data/Events/Intermediate').\n",
    "        filename_pattern (str): The pattern to match (e.g., '*_event_sponsor.csv').\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: The DataFrame of the latest file, or None if no files are found or reading fails.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(event_sponsor_dir):\n",
    "        print (f\"‚ùå{event_sponsor_dir} does not exist as a directory\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS)   \n",
    "    \n",
    "    # Get csv files in \n",
    "    files = glob.glob(f\"{event_sponsor_dir}/*.csv\")\n",
    "   \n",
    "\n",
    "    event_sponsor_files = []\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ùå No existing *.csv files found in EVENTS_SPONSORS  Directory: {event_sponsor_dir} \")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None  \n",
    "\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)\n",
    "       \n",
    "        if re.match(event_sponsor_regex,filename):\n",
    "           event_sponsor_files.append(file)\n",
    "\n",
    "    if not event_sponsor_files:\n",
    "        print(f\"‚ùå No existing EVENTS_SPONSORS files in format: {event_sponsor_regex} in {event_sponsor_dir}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS)   \n",
    "    event_sponsor_files.sort()    \n",
    "    latest_event_sponsor = event_sponsor_files[-1]\n",
    "\n",
    "    try: \n",
    "        latest_event_sponsor_df = pd.read_csv(latest_event_sponsor)\n",
    "        print(f\"‚úÖ {len(latest_event_sponsor_df)} events found in latest EVENTS_SPONSORS: {latest_event_sponsor} \")\n",
    "        return latest_event_sponsor_df, latest_event_sponsor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"‚ùå Error reading lastest EVENTS_SPONSORS, {file}: {e}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e2b2f78f-7de8-49c2-a2bb-237b58a37670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_intermediate_events(intermediate_events_dir:str, intermediate_events_regex) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parses specified directory for events files in format yyyy_mm_dd. \n",
    "    Attempts to read latest file in this format. \n",
    "\n",
    "    Args:\n",
    "        directory (str): The folder where the intermediate files are stored (e.g., '../Data/Events/Intermediate').\n",
    "        filename_pattern (str): The pattern to match (e.g., '*_events_intermediate.csv').\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: The DataFrame of the latest file, or None if no files are found or reading fails.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(intermediate_events_dir):\n",
    "        print (f\"‚ùå{intermediate_events_dir} does not exist as a directory\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None   \n",
    "    \n",
    "    # Get csv files in \n",
    "    files = glob.glob(f\"{intermediate_events_dir}/*.csv\")\n",
    "   \n",
    "\n",
    "    intermediate_files = []\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"‚ùå No existing *.csv files found in INTERMEDIATE Events Directory: {intermediate_events_dir} \")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None\n",
    "\n",
    "    for file in files:\n",
    "        filename = os.path.basename(file)\n",
    "       \n",
    "        if re.match(intermediate_events_regex,filename):\n",
    "           intermediate_files.append(file)\n",
    "\n",
    "    if not intermediate_files:\n",
    "        print(f\"‚ùå No existing INTERMEDIATE files in format: {intermediate_events_regex} in {intermediate_events_dir}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS),None \n",
    "    intermediate_files.sort()    \n",
    "    latest_intermediate = intermediate_files[-1]\n",
    "\n",
    "    try: \n",
    "        latest_intermediate_df = pd.read_csv(latest_intermediate)\n",
    "        print(f\"‚úÖ {len(latest_intermediate_df)} events found in latest INTERMEDIATE: {latest_intermediate} \")\n",
    "        return latest_intermediate_df, latest_intermediate\n",
    "        \n",
    "    except Exception as e:\n",
    "        print (f\"‚ùå Error reading lastest INTERMEDIATE, {latest_intermediate}: {e}\")\n",
    "        return pd.DataFrame(columns=MINIMAL_EVENT_COLUMNS), None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7c50eb17-9a28-477f-a299-eaf49af3efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_sponsor_ids(df: pd.DataFrame,sponsor:str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Identifies events in the DataFrame that already have valid sponsor data \n",
    "    (i.e., BallSponsor or TableSponsor is not 'TBC' and not None).\n",
    "    Returns a list of these event is.\n",
    "    \"\"\"\n",
    "    # Identify rows where either sponsor column is NOT 'TBC' AND NOT NaN.\n",
    "    #'|' to see if either column has data \n",
    "    # TBC means no sponsor data has been searched for \n",
    "    # None means no sponsor data was found previously\n",
    "\n",
    "    unenriched_mask = (df[sponsor] == 'TBC)') | (df[sponsor].isnull())\n",
    "    \n",
    "    ids = list(set(df[unenriched_mask]['eventId'].tolist()))\n",
    "\n",
    "   \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "caa44250-e151-4ca1-9ae5-59f06977ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sponsors(event_id:Union[int,str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Function used for parralel, threaded api calls to fetch sponsor details,\n",
    "    for one event specified by event_id. Returns dict of ball and table sponsor\n",
    "       \n",
    "    Returns:\n",
    "        (sponsors_list)  A list of sponsors data direct from the API \n",
    "    \"\"\"   \n",
    "    \n",
    "    # define api url and headers.\n",
    "    url = f\"https://wtt-website-api-prod-3-frontdoor-bddnb2haduafdze9.a01.azurefd.net/api/cms/GetEventEquipmentwithLogo/{event_id}\" \n",
    "    headers = {\n",
    "        \"accept\": \"application/json, text/plain, */*\",\n",
    "        \"accept-language\": \"en-GB,en;q=0.9,es=q=0.8\",\n",
    "        \"cache-control\": \"no-cache\",\n",
    "        \"dnt\": \"1\",\n",
    "        \"origin\": \"https://www.worldtabletennis.com\",\n",
    "        \"pragma\": \"no-cache\",\n",
    "        \"priority\": \"u=1, i\",\n",
    "        \"referer\": \"https://www.worldtabletennis.com/\",\n",
    "        \"sec-ch-ua\": \"\\\"Chromium\\\";v=\\\"140\\\", \\\"Not=A?Brand\\\";v=\\\"24\\\", \\\"Google Chrome\\\";v=\\\"140\\\"\",\n",
    "        \"sec-ch-ua-mobile\": \"?1\",\n",
    "        \"sec-ch-ua-platform\": \"\\\"Android\\\"\",\n",
    "        \"sec-fetch-dest\": \"empty\",\n",
    "        \"sec-fetch-mode\": \"cors\",\n",
    "        \"sec-fetch-site\": \"cross-site\",\n",
    "        \"secapimkey\": \"S_WTT_882jjh7basdj91834783mds8j2jsd81\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Linux; Android 11.0; Surface Duo) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Mobile Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "   \n",
    "\n",
    "    # make the api call and get response as a json. Raise errors if they occur\n",
    "    try:       \n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        # raise an error for bad status codes (4xx or 5xx)\n",
    "        response.raise_for_status()         \n",
    "        sponsors_json = response.json()\n",
    "\n",
    "        #  check that response contains data and is a list:        \n",
    "        if sponsors_json and isinstance(sponsors_json,list):  \n",
    "            print(f\"Obtained Raw Sponsors API Data for {event_id}\")          \n",
    "            return pd.DataFrame(sponsors_json)\n",
    "        \n",
    "   \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        status_msg = f\"HTTP Error {e.response.status_code}\"\n",
    "        print(f\"--- ‚ùå [{event_id}] Failed:\") \n",
    "    except requests.exceptions.Timeout:\n",
    "        status_msg = \"Timeout\"\n",
    "        print(f\"--- ‚ùå [{event_id}] Failed: \") \n",
    "    except Exception as e:\n",
    "        status_msg = f\"Unexpected Error {type(e).__name__}: {e}\"\n",
    "        print(f\"--- ‚ùå [{event_id}] Failed: {e}\") # Log unexpected errors\n",
    "\n",
    "    # Pause for API politness before returning None and continuing\n",
    "   \n",
    "   \n",
    "    return None\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "14bd5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sponsor_name(sponsor_row, links_map, logos_map):\n",
    "    \"\"\"\n",
    "    Tries to map a sponsor name, first by link, then by logo.\n",
    "    \"\"\"    \n",
    "    links_map = json.load(open(LINKS_MAP_FILE))\n",
    "    logos_map = json.load(open(LOGOS_MAP_FILE))\n",
    "    if sponsor_row is None:\n",
    "        return None\n",
    "        \n",
    "    # 1. Try to map the sponsorLink\n",
    "    link = sponsor_row.get(\"sponsorLink\")\n",
    "    name = links_map.get(link)\n",
    "    \n",
    "    # 2. If mapping the link fails, fall back to mapping the logo\n",
    "    if name is None:\n",
    "        logo = sponsor_row.get(\"logo\")\n",
    "        name = logos_map.get(logo)\n",
    "        \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6773c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 187 events found in latest INTERMEDIATE: ../Data/Processed/Events/Intermediate/20251110_intermediate_events.csv \n",
      "‚úÖ 186 events found in latest EVENTS_SPONSORS: ../Data/Processed/Sponsors/20251108_event_sponsors.csv \n",
      "--- üü¢ Commencing Sponsor Scrape üü¢---\n",
      "Processing Event: 1/27 (ID: 3066)    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained Raw Sponsors API Data for 3066\n",
      "Obtained Raw Sponsors API Data for 3191\n",
      "\n",
      "--- üèì Found new Ball Sponsor for Event ID: 3191 üèì---\n",
      "Obtained Raw Sponsors API Data for 2591\n",
      "Obtained Raw Sponsors API Data for 2537\n",
      "Processing Event: 27/27 (ID: 2234)    \n",
      "--- ‚úÖ Scraping complete. Consolidating results... ---\n",
      "--- Found 4 events with new sponsor data. ---\n",
      "--- Combining 4 new sponsor records with existing data... ---\n",
      "--- üü¢ Successfully saved 187 total sponsored events to ../Data/Processed/Sponsors/20251110_event_sponsors.csv üü¢---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "\n",
    "    now_date_str = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    \n",
    "    \n",
    "    intermediate_df, _ = get_latest_intermediate_events(INTERMEDIATE_EVENTS_DIR, INTERMEDIATE_EVENTS_REGEX)\n",
    "    if intermediate_df.empty:\n",
    "        print(\"‚ùå FAILURE: Missing intermediate data\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    \n",
    "    event_sponsors_df, event_sponsors_file = get_latest_event_sponsor(EVENTS_SPONSORS_DIR, EVENTS_SPONSORS_REGEX)\n",
    "    if event_sponsors_df.empty:\n",
    "        print (\"‚ùå FAILURE: Missing event sponsor data\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    latest_sponsors_date_str = os.path.basename(event_sponsors_file).split(\"_\")[0]\n",
    "    latest_sponsors_date = pd.to_datetime(latest_sponsors_date_str)\n",
    "    \n",
    "    existing_sponsor_ids = event_sponsors_df[\"eventId\"].to_list()\n",
    "    new_sponsor_mask = intermediate_df[\"eventId\"].isin(existing_sponsor_ids)\n",
    "    new_ids = intermediate_df[~new_sponsor_mask][\"eventId\"].tolist()\n",
    "   \n",
    "   \n",
    "        \n",
    "    # get IDS which can still be scraped if info is available!\n",
    "    missing_ball_ids = get_missing_sponsor_ids(event_sponsors_df,\"BallSponsor\") + new_ids\n",
    "    missing_ball_set = set(missing_ball_ids)\n",
    "\n",
    "    missing_table_ids = get_missing_sponsor_ids(event_sponsors_df,\"TableSponsor\") + new_ids\n",
    "    missing_table_set = set(missing_table_ids)\n",
    "\n",
    "    intermediate_df[\"StartDate\"] = pd.to_datetime(intermediate_df[\"StartDate\"])\n",
    "    unupdated_events_filter = intermediate_df[\"StartDate\"] > latest_sponsors_date\n",
    "    unupdated_ids = intermediate_df[unupdated_events_filter][\"eventId\"].tolist()\n",
    "\n",
    "    ids_to_scrape = missing_ball_set.union(missing_table_set)\n",
    "    # ids_to_scrape = [event_id for event_id in ids_to_scrape if event_id in unupdated_ids]\n",
    "    ids_to_scrape = set(ids_to_scrape).union(new_ids)\n",
    "    ids_to_scrape = list(ids_to_scrape)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    new_sponsor_data = []\n",
    "\n",
    "    print(\"--- üü¢ Commencing Sponsor Scrape üü¢---\")\n",
    "    try:\n",
    "        with open(LINKS_MAP_FILE, 'r') as f:\n",
    "            LOADED_LINKS_MAP = json.load(f)\n",
    "        with open(LOGOS_MAP_FILE, 'r') as f:\n",
    "            LOADED_LOGOS_MAP = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Could not load sponsor map files. {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    for i, event_id in enumerate(ids_to_scrape):\n",
    "    \n",
    "        print(f\"Processing Event: {i+1}/{len(ids_to_scrape)} (ID: {event_id})    \\r\", end=\"\", flush=True)\n",
    "        \n",
    "        # Request to get sponsors details from API call \n",
    "        sponsors_df = get_sponsors(event_id)\n",
    "        # If response is bad / None/ empty, skip to next event to check\n",
    "        if sponsors_df is None or sponsors_df.empty:            continue\n",
    "        \n",
    "        \n",
    "        # Find the *first* row that matches \"ball\"\n",
    "        ball_sponsor_row = sponsors_df[\n",
    "            sponsors_df[\"sponsorTypeName\"].str.contains(\"ball\", case=False, na=False)\n",
    "        ].iloc[0] if not sponsors_df[sponsors_df[\"sponsorTypeName\"].str.contains(\"ball\", case=False, na=False)].empty else None\n",
    "        \n",
    "        # Find the *first* row that matches \"table\"\n",
    "        table_sponsor_row = sponsors_df[\n",
    "            sponsors_df[\"sponsorTypeName\"].str.contains(\"table\", case=False, na=False)\n",
    "        ].iloc[0] if not sponsors_df[sponsors_df[\"sponsorTypeName\"].str.contains(\"table\", case=False, na=False)].empty else None\n",
    "\n",
    "        # try to map data \n",
    "\n",
    "        ball_sponsor_name = map_sponsor_name(ball_sponsor_row, LINKS_MAP_FILE, LOGOS_MAP_FILE)\n",
    "        table_sponsor_name = map_sponsor_name(table_sponsor_row, LINKS_MAP_FILE, LOGOS_MAP_FILE)\n",
    "\n",
    "        found_new_ball = ball_sponsor_name and (event_id in missing_ball_set)\n",
    "        found_new_table = table_sponsor_name and (event_id in missing_table_set)\n",
    "\n",
    "        # Only proceed if we found at least one *new* piece of data\n",
    "        if found_new_ball or found_new_table:            \n",
    "            # Log the success\n",
    "            found_items = []\n",
    "            if found_new_ball:\n",
    "                found_items.append(\"Ball Sponsor\")\n",
    "            if found_new_table:\n",
    "                found_items.append(\"Table Sponsor\")\n",
    "            \n",
    "            found_str = \" and \".join(found_items)\n",
    "            print(f\"\\n--- üèì Found new {found_str} for Event ID: {event_id} üèì---\", flush=True)\n",
    "\n",
    "        \n",
    "        new_sponsor_data.append({\n",
    "            \"eventId\": event_id,\n",
    "            \"BallSponsor\": ball_sponsor_name if found_new_ball else None,\n",
    "            \"TableSponsor\": table_sponsor_name if found_new_table else None\n",
    "        })\n",
    "\n",
    "\n",
    "    print(\"\\n--- ‚úÖ Scraping complete. Consolidating results... ---\")\n",
    "    new_sponsor_df = pd.DataFrame(new_sponsor_data)\n",
    "   \n",
    "    if new_sponsor_df.empty:\n",
    "        print(\"--- ‚ö†Ô∏è No new sponsor data was found for any missing events sponsors. ---\")\n",
    "    else:\n",
    "        print(f\"--- Found {len(new_sponsor_df)} events with new sponsor data. ---\")##\n",
    "\n",
    "    if not new_sponsor_df.empty:\n",
    "        print(f\"--- Combining {len(new_sponsor_df)} new sponsor records with existing data... ---\")\n",
    "    \n",
    "\n",
    "        SPONSOR_COLUMNS = ['eventId', 'BallSponsor', 'TableSponsor']\n",
    "  \n",
    "        event_sponsors_df = event_sponsors_df.set_index(\"eventId\")\n",
    "        new_sponsor_df = new_sponsor_df.set_index(\"eventId\")\n",
    "        combined_df = new_sponsor_df.combine_first(event_sponsors_df)\n",
    "        final_sponsors_df = combined_df.reset_index()\n",
    "\n",
    "        try:\n",
    "            date_string = now_date_str\n",
    "            final_sponsors_name = f\"{date_string}{EVENTS_SPONSORS_SUFFIX}\"\n",
    "            final_sponsors_path = os.path.join(EVENTS_SPONSORS_DIR,final_sponsors_name)\n",
    "            final_sponsors_df.to_csv(final_sponsors_path, index=False)\n",
    "            print(f\"--- üü¢ Successfully saved {len(final_sponsors_df)} total sponsored events to {final_sponsors_path} üü¢---\")\n",
    "        except Exception as e:\n",
    "            print(f\"--- ‚ùå FAILED to save updated sponsor file: {e} ---\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001165f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table_tennis_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
