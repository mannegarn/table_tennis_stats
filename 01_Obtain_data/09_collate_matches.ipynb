{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4672559f-3903-4cec-bd15-016c5da479a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import glob \n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, date\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "import random \n",
    "import time \n",
    "import numpy as np\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee7fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_MATCH_DETAILS_DIR = \"../Data/Raw/Match_details\"\n",
    "\n",
    "DNF_KEYWORDS = ['WO', 'INJ', 'RET', 'DSQ']\n",
    "DNF_PATTERN = '|'.join(DNF_KEYWORDS)\n",
    "DNF_PATTERN_CAPTURE = r'(' + r'|'.join(DNF_KEYWORDS) + r')'\n",
    "\n",
    "drop_columns = [\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9f8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_match_details_files = glob.glob(os.path.join(RAW_MATCH_DETAILS_DIR, \"*.json\"))\n",
    "all_matches = []\n",
    "for file in all_match_details_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        matches_data = json.load(f)\n",
    "\n",
    "    all_matches.extend(matches_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbd0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_df = pd.DataFrame(all_matches)\n",
    "age_limit_mask = all_matches_df['subEventName'].str.contains(r\"U\\d{2}\", case=False, na=False)\n",
    "para_class_mask = all_matches_df['subEventName'].str.contains(\"class\", case=False, na=False)\n",
    "my_filter = age_limit_mask | para_class_mask\n",
    "\n",
    "# a df without any para or age limited matches (i.e all in same event / class except for gender split)\n",
    "cleaned_matches_df = all_matches_df[~my_filter].copy()\n",
    "cleaned_matches_df[\"dnf\"] = cleaned_matches_df[\"overallScores\"].str.extract(DNF_PATTERN_CAPTURE, expand=False).str.strip()\n",
    "#rejected_matches_df = all_matches_df[my_filter].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4e6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Add dnf column. ads dnf reason or sets to FALSE    \n",
    "cleaned_matches_df[\"dnf\"] = cleaned_matches_df[\"overallScores\"].str.extract(DNF_PATTERN_CAPTURE, expand=False).str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30cca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_player_details_raw(competitor_list):\n",
    "    \"\"\"\n",
    "    Extracts name and ID details for Home (H) and Away (A) competitors\n",
    "    by pulling the raw data directly from the 'competitiors' column.\n",
    "    \n",
    "    NO parsing or splitting of names is performed.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {\n",
    "        'home_player_id': pd.NA,\n",
    "        'home_player_name': pd.NA,\n",
    "        'home_given_name': pd.NA,\n",
    "        'home_family_name': pd.NA,\n",
    "        'away_player_id': pd.NA,\n",
    "        'away_player_name': pd.NA,\n",
    "        'away_given_name': pd.NA,\n",
    "        'away_family_name': pd.NA,\n",
    "    }\n",
    "    \n",
    "    # Safety check for empty or malformed data\n",
    "    if not isinstance(competitor_list, list) or len(competitor_list) < 2:\n",
    "        return pd.Series(data)\n",
    "\n",
    "    try:\n",
    "        for comp in competitor_list:\n",
    "            comp_type = comp.get('competitorType')\n",
    "            \n",
    "            if comp_type == 'H':\n",
    "                prefix = 'home_'\n",
    "            elif comp_type == 'A':\n",
    "                prefix = 'away_'\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            # Safely get the (first) player dict, or an empty dict\n",
    "            player_info = comp.get('players', [{}])[0]\n",
    "            \n",
    "            # --- Direct Extraction (No Parsing) ---\n",
    "            \n",
    "            # 1. Get ID (fallback from player-level to competitor-level)\n",
    "            data[f'{prefix}player_id'] = player_info.get('playerId', comp.get('competitiorId', pd.NA))\n",
    "            \n",
    "            # 2. Get Player Name (fallback from player-level to competitor-level)\n",
    "            data[f'{prefix}player_name'] = player_info.get('playerName', comp.get('competitiorName', pd.NA))\n",
    "            \n",
    "            # 3. Get Given Name (raw)\n",
    "            data[f'{prefix}given_name'] = player_info.get('playerGivenName', pd.NA)\n",
    "            \n",
    "            # 4. Get Family Name (raw)\n",
    "            data[f'{prefix}family_name'] = player_info.get('playerFamilyName', pd.NA)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e} | Data: {competitor_list}\")\n",
    "        pass\n",
    "\n",
    "    return pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2702203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Event:      ... (Flattening competitor data - raw)\n",
      "✅ Competitor details extracted and appended (as is).\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Event:      ... (Flattening competitor data - raw)\")\n",
    "\n",
    "# 1. Apply the function to the 'competitiors' column\n",
    "player_details_df = cleaned_matches_df['competitiors'].apply(extract_player_details_raw)\n",
    "\n",
    "# 2. Join the new columns back to the main DataFrame\n",
    "cleaned_matches_df = pd.concat(\n",
    "    [cleaned_matches_df.drop(player_details_df.columns, axis=1, errors='ignore'), \n",
    "     player_details_df], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"✅ Competitor details extracted and appended (as is).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f1201c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any matches where the away player name contains a number\n",
    "home_contains_digit = cleaned_matches_df[\"home_player_name\"].str.contains(r\"[0-9]\", na=False)\n",
    "away_contains_digit = cleaned_matches_df[\"away_player_name\"].str.contains(r\"[0-9]\", na=False)\n",
    "keep_filter = ~(home_contains_digit | away_contains_digit)\n",
    "cleaned_matches_df = cleaned_matches_df[keep_filter].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c9ae7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 23547\n",
      "after: 23547\n"
     ]
    }
   ],
   "source": [
    "print(f\"before: {len(cleaned_matches_df)}\")\n",
    "away_given_name_contains_digit = cleaned_matches_df[\"away_given_name\"].str.contains(r\"[0-9]\", na=False)\n",
    "away_family_name_contains_digit = cleaned_matches_df[\"away_family_name\"].str.contains(r\"[0-9]\", na=False)\n",
    "home_given_name_contains_digit = cleaned_matches_df[\"home_given_name\"].str.contains(r\"[0-9]\", na=False)\n",
    "home_family_name_contains_digit = cleaned_matches_df[\"home_family_name\"].str.contains(r\"[0-9]\", na=False)\n",
    "keep_filter = ~(away_given_name_contains_digit | away_family_name_contains_digit | home_given_name_contains_digit | home_family_name_contains_digit)\n",
    "cleaned_matches_df = cleaned_matches_df[keep_filter].copy()\n",
    "print(f\"after: {len(cleaned_matches_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab87272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 23547\n",
      "after: 23547\n"
     ]
    }
   ],
   "source": [
    "print(f\"before: {len(cleaned_matches_df)}\")\n",
    "home_name_contains_team = cleaned_matches_df[\"home_player_name\"].str.contains(\"team\", case=False, na=False)\n",
    "away_name_contains_team = cleaned_matches_df[\"away_player_name\"].str.contains(\"team\", case=False, na=False)\n",
    "home_given_name_contains_team = cleaned_matches_df[\"home_given_name\"].str.contains(\"team\", case=False, na=False)\n",
    "away_given_name_contains_team = cleaned_matches_df[\"away_given_name\"].str.contains(\"team\", case=False, na=False)\n",
    "home_family_name_contains_team = cleaned_matches_df[\"home_family_name\"].str.contains(\"team\", case=False, na=False)\n",
    "away_family_name_contains_team = cleaned_matches_df[\"away_family_name\"].str.contains(\"team\", case=False, na=False)\n",
    "keep_filter = ~(home_name_contains_team | away_name_contains_team | home_given_name_contains_team | away_given_name_contains_team | home_family_name_contains_team | away_family_name_contains_team)\n",
    "cleaned_matches_df = cleaned_matches_df[keep_filter].copy()\n",
    "print(f\"after: {len(cleaned_matches_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b0f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table_tennis_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
