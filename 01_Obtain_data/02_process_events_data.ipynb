{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c2cef5a-6784-4db7-b7c6-e35d805b67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Union, Tuple\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f4ed16-f2fb-4782-9adc-dfbad43642d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script reads and filters events data that have been scraped by year. \n",
    "All desired events are saved into an events_shortlist. ALl removed events are also savec\n",
    "\"\"\"\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Define directory where events by year files are stored as csv.\n",
    "EVENTS_DIRECTORY = \"../Data/Raw/Events\"\n",
    "\n",
    "# Output directory where the master file will be saved\n",
    "OUTPUT_DIRECTORY =\"../Data/Processed/Events\"\n",
    "\n",
    "SHORTLIST_OUTPUT_NAME = \"shortlist_events.csv\"\n",
    "\n",
    "REMOVED_OUTPUT_NAME = \"removed_events.csv\"\n",
    "\n",
    "REMOVE_STRINGS = {\n",
    "    # Non-Senior events\n",
    "    \"cadet\", \n",
    "    \"junior\", \n",
    "    \"youth\",\n",
    "    \"under\",\n",
    "    # Para Categories\n",
    "    \"para\", \n",
    "    \"paralympic\",     \n",
    "    # Veteran series\n",
    "    \"vet\", \n",
    "    \"veteran\"\n",
    "}\n",
    "\n",
    "# Regex pattern used to filter out age restricted events (e.g U13, U21 etc)\n",
    "AGE_PATTERN = r\"u\\d{2}\"\n",
    "\n",
    "\n",
    "# This can be used to rename events after filtering for increased clarity\n",
    "# Passed into the rename_events function.\n",
    "NAME_MAP = {\n",
    "    \"Singles World Cup\": \"World Cup\",\n",
    "    \"WTT Cup Finals\": \"WTT Finals\",\n",
    "    \"WTTC\": \"World Championship\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ebd73e5-e17e-40c9-853a-eb685d084677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_raw_events (directory: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads all individual event CSV files from the specified directory and compiles them \n",
    "    into a single DataFrame.\n",
    "    \"\"\"\n",
    "    all_events_list = [] \n",
    "    print(\"--- 🟠 Combining Raw Event Files 🟠 ---\")\n",
    "\n",
    "    # Iterate through csv files in search directory\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            \n",
    "            print(f\"Reading file: {file}\")\n",
    "    \n",
    "            # using os.path.join to create the full file path from the directory and filename\n",
    "            # read the file, convert to DF, ana store in all_events_list container.\n",
    "            \n",
    "            full_path = os.path.join(directory, file)\n",
    "            df = pd.read_csv(full_path)\n",
    "            all_events_list.append(df)\n",
    "\n",
    "    if not all_events_list:\n",
    "        print(f\"❌ Error: No CSV files found in {directory}.\")\n",
    "        # Return blank DataFrame if no data found\n",
    "        return pd.DataFrame() \n",
    "\n",
    "    all_events_df = pd.concat(all_events_list, ignore_index=True)\n",
    "    \n",
    "    all_events_df.rename(columns={'EventId': 'eventId'}, inplace=True)\n",
    "\n",
    "    return all_events_df\n",
    "\n",
    "    \n",
    "def filter_selected_events(df: pd.DataFrame,\n",
    "                           remove_strings: List[str],\n",
    "                           age_pattern: str\n",
    "                           ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Filters a dataframe of events data in order to keep only the desired events as specified by the inputs.\n",
    "    Here: Keeping all standard, senior events. Checks event names and event types for patterns to be removed.\n",
    "    Returns a tuple of [kept_df, removed_df\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 🟠 Filtering from {len(df)} Events 🟠 ---\")\n",
    "\n",
    "\n",
    "\n",
    "    # Create a copy of the df for the function scope and remove duplicates from it.\n",
    "    function_df = df.copy()\n",
    "    function_df = function_df.drop_duplicates(subset=[\"eventId\"], keep = \"first\", inplace = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "  \n",
    "    # here \"|\" denotes \"OR\" for regex pattern. If the event name has any of these terms it will be removed\n",
    "    string_pattern = \"|\".join(remove_strings)\n",
    "    \n",
    "    # create a mask for conditions to filter the DF - here select all event names with those strings.\n",
    "    string_mask = (function_df[\"EventName\"].str.contains(string_pattern, case=False, na=False) | \n",
    "                 function_df[\"EventType\"].str.contains(string_pattern, case=False, na=False))\n",
    "                 \n",
    "    # mask for age using age pattern as defined in config (UXX regex to remove U13, U21 etc)\n",
    "    age_mask = (function_df[\"EventName\"].str.contains(age_pattern, case=False, na=False) | \n",
    "                 function_df[\"EventType\"].str.contains(age_pattern, case=False, na=False))\n",
    "                                                      \n",
    "    # define a mask to check event name and type for any strings to be removed.\n",
    "    remove_mask = string_mask | age_mask\n",
    "\n",
    "    # use filter condition ~mask to select entries that DO NOT contain the filtered patterns.\n",
    "    kept_df = function_df[~remove_mask].copy() \n",
    "    # use filter condition ~mask to select entries that  contain the filtered patterns.\n",
    "    removed_df = function_df[remove_mask].copy()\n",
    "\n",
    "    print(f\"From total: {len(df)} events , kept: {len(kept_df)}, removed: {len(removed_df)}, duplicates: {len(df) - len(function_df)}\") \n",
    "    \n",
    "    return kept_df, removed_df\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "def standardize_event_names(df: pd.DataFrame, name_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Changes event names from the original event list to simpler names for Clarity.\n",
    "    e.g., ['Singles World Cup', \"WTTC\"] to [\"World Cup\", \"World Championships\"]\n",
    "    \n",
    "    World Cup (newer, annual) and World Championship (older, biannnual) are often confused.\n",
    "    Name changes can be specified in name_map variable.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Use .loc to explicitly change names of input df.\n",
    "    df[\"EventType\"] = df[\"EventType\"].replace(name_map)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_dates(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Converts the dates in the events data to pd.datetime objects for easier processing.\n",
    "    Current format returned by WTT API is (YYYY-MM-DDTHH:MM:SS)\n",
    "    \"\"\"\n",
    "    # create a copy for safety\n",
    "    working_df = df.copy()\n",
    "    \n",
    "    \n",
    "    working_df['StartDateTime'] = pd.to_datetime(working_df['StartDateTime'])\n",
    "    working_df['EndDateTime'] = pd.to_datetime(working_df['EndDateTime'])\n",
    "\n",
    "    return  working_df\n",
    "\n",
    "def tag_event_status(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds a column to flag events that are currently ongoing or in the future.\n",
    "    completed events , completed = True, future and ongoing events, completed = False\n",
    "    This uses the Start and End dates from api response. There are fields for rearranged start and end times.\n",
    "    But these are blank for all relevant events and so only StartDate and EndDate from api will be considered.\n",
    "    \"\"\"\n",
    "    # create a copy for safety and ensure datetimes are used\n",
    "    working_df = df.copy()\n",
    "    working_df['EndDateTime'] = pd.to_datetime(working_df['EndDateTime'])\n",
    "    working_df['StartDateTime'] = pd.to_datetime(working_df['StartDateTime'])\n",
    "    \n",
    "    # create utc times for yesterday and tomorrow for one day buffer in the dates\n",
    "    # this is used as it is not clear what time zone the events data is in \n",
    "    now_utc = pd.to_datetime(datetime.now(timezone.utc))\n",
    "    yesterday_utc = now_utc - timedelta(days=1)\n",
    "    tomorrow_utc = now_utc + timedelta(days=1)\n",
    "\n",
    "    yesterday = yesterday_utc.replace(tzinfo=None)\n",
    "    tomorrow = tomorrow_utc.replace(tzinfo=None)\n",
    "    now = now_utc.replace(tzinfo=None)\n",
    "    \n",
    "    # Tag True if the EndDateTime is in the future relative to 'now'\n",
    "    working_df['EventStatus'] = np.select(\n",
    "    # Array of Conditions (checked in order)\n",
    "    condlist=[\n",
    "        #  Completed: end time is in past (i.e it completed before yesterday)\n",
    "        working_df['EndDateTime'] < yesterday,\n",
    "        \n",
    "        # Future: if it starts / started  before tomorrow\n",
    "        working_df['StartDateTime'] > tomorrow,\n",
    "    ],\n",
    "    # Array of Corresponding Values\n",
    "    choicelist=[\n",
    "        'Completed', \n",
    "        'Future',     \n",
    "    ],\n",
    "    # Default Value (If neither condition above is met)\n",
    "    default='Ongoing')\n",
    "    \n",
    "    return  working_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67bbb0ad-d98d-4f7a-a3f0-99889602c5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---🚀 Starting WTT Event Processing 🚀---\n",
      "--- 🟠 Combining Raw Event Files 🟠 ---\n",
      "Reading file: raw_events_2022.csv\n",
      "Reading file: raw_events_2025.csv\n",
      "Reading file: raw_events_2020.csv\n",
      "Reading file: raw_events_2023.csv\n",
      "Reading file: raw_events_2024.csv\n",
      "Reading file: raw_events_2021.csv\n",
      "\n",
      "--- 🟠 Filtering from 676 Events 🟠 ---\n",
      "From total: 676 events , kept: 302, removed: 328, duplicates: 46\n",
      "✅ Kept 302 events saved to ../Data/Processed/Events/shortlist_events.csv\n",
      "✅ Removed 328 events saved to ../Data/Processed/Events/removed_events.csv\n",
      "\n",
      "---🟢 Processing finished. 🟢---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"---🚀 Starting WTT Event Processing 🚀---\")\n",
    "    \n",
    "    # Create the output directory if it does not exist.\n",
    "    os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)     \n",
    "    \n",
    "    # Load and combine all raw data\n",
    "    raw_events_df = collate_raw_events(EVENTS_DIRECTORY)\n",
    "    \n",
    "    if raw_events_df.empty:\n",
    "        print(\"--- ❌ Processing failed: No raw data loaded. Check the input directory. ---\")\n",
    "    else:\n",
    "        \n",
    "        # Filter out events as specified\n",
    "        # This returns seperate df for kept and removed events.\n",
    "        kept_df, removed_df = filter_selected_events(\n",
    "            df=raw_events_df,                     \n",
    "            remove_strings=REMOVE_STRINGS,\n",
    "            age_pattern = AGE_PATTERN\n",
    "        )\n",
    "\n",
    "        # convert the dates \n",
    "        time_converted_df = convert_dates(kept_df)\n",
    "        # tag if event is ongoing for easier future processing\n",
    "        tagged_df = tag_event_status(time_converted_df)       \n",
    "        \n",
    "            \n",
    "        # Standardize the event names for consistency - only for the kept_df        \n",
    "        shortlist_df = standardize_event_names(\n",
    "            df=tagged_df, \n",
    "            name_map=NAME_MAP\n",
    "        )\n",
    "        \n",
    "        # Sort by Date for consistency\n",
    "        shortlist_df = shortlist_df.sort_values([\"StartDateTime\"])\n",
    "        removed_df = removed_df.sort_values([\"StartDateTime\"])\n",
    "        \n",
    "        # Sort the shortlist_df        \n",
    "        shortlist_path = os.path.join(OUTPUT_DIRECTORY, f\"{SHORTLIST_OUTPUT_NAME}\")\n",
    "        shortlist_df.to_csv(shortlist_path, index=False)\n",
    "        print(f\"✅ Kept {len(shortlist_df)} events saved to {shortlist_path}\")\n",
    "\n",
    "        # Save the removed_df so that it can be checkedabs\n",
    "\n",
    "        removed_path = os.path.join(OUTPUT_DIRECTORY, f\"{REMOVED_OUTPUT_NAME}\")\n",
    "        removed_df.to_csv(removed_path, index=False)\n",
    "        print(f\"✅ Removed {len(removed_df)} events saved to {removed_path}\")        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    print(\"\\n---🟢 Processing finished. 🟢---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a9a2e-2b6e-4331-86de-14027e1ce45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f93af3-d2f5-4cb8-b76f-3972d8fd24fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table_tennis_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
