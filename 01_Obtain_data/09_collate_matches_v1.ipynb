{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import pycountry\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_MATCH_DETAILS_DIR = \"../Data/Raw/Match_details\"\n",
    "\n",
    "DNF_KEYWORDS = ['WO', 'INJ', 'RET', 'DSQ', 'DNS']\n",
    "DNF_PATTERN = '|'.join(DNF_KEYWORDS)\n",
    "DNF_PATTERN_CAPTURE = r'(' + r'|'.join(DNF_KEYWORDS) + r')'\n",
    "\n",
    "TEAM_NAME_PATTERN = r'team|federacion|federation|table'\n",
    "\n",
    "DROP_COLUMNS_START = [\"resultStatus\", \"tableName\", \"tableNumber\",\"venueName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all match files in the RAW_MATCH_DETAILS_DIR\n",
    "# Create an all_matches_df to be filtered down \n",
    "# Many of these matches are in fact match ups between teams rather than players - need to filter out.\n",
    "# some of the singles matches are from teams matches and events - can keep these.\n",
    "\n",
    "\n",
    "\n",
    "# parse all match details inside the json files.\n",
    "all_match_details_files = glob.glob(os.path.join(RAW_MATCH_DETAILS_DIR, \"*.json\"))\n",
    "all_matches = []\n",
    "for file in all_match_details_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        matches_data = json.load(f)\n",
    "\n",
    "    all_matches.extend(matches_data)\n",
    "\n",
    "# create the df \n",
    "\n",
    "all_matches_df = pd.DataFrame(all_matches)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_matches_df before dropping empty rows and columns: 24469\n",
      "cleaned_matches_df after dropping empty rows and columns: 24469\n",
      "âœ… 'dnf' column updated by sequentially filling missing values from 'overallScores' THEN 'resultOverallScores'.\n"
     ]
    }
   ],
   "source": [
    "# Keep here inside this cell to prevent rerunning file parsing and extraction every time.\n",
    "all_matches_df = pd.DataFrame(all_matches)\n",
    "\n",
    "# drop some columns that are not currently of interest for the project (e.g table number and venue etc )\n",
    "all_matches_df.drop(columns=DROP_COLUMNS_START, inplace=True)\n",
    "\n",
    "\n",
    "# initialise the cleaned matches df and drop empty columns and na rows\n",
    "print(f\"all_matches_df before dropping empty rows and columns: {len(all_matches_df)}\")\n",
    "cleaned_matches_df = all_matches_df.dropna(axis=0, how='all', inplace=False)\n",
    "cleaned_matches_df = all_matches_df.dropna(axis=0, how='all', inplace=False)\n",
    "print(f\"cleaned_matches_df after dropping empty rows and columns: {len(cleaned_matches_df)}\")\n",
    "\n",
    "\n",
    "dnf_from_overallScores = cleaned_matches_df[\"overallScores\"].str.extract(DNF_PATTERN_CAPTURE, expand=False).str.strip()\n",
    "dnf_from_resultoverallScores = cleaned_matches_df[\"resultOverallScores\"].str.extract(DNF_PATTERN_CAPTURE, expand=False).str.strip()\n",
    "\n",
    "cleaned_matches_df[\"dnf\"] = dnf_from_overallScores\n",
    "cleaned_matches_df[\"dnf\"] = cleaned_matches_df[\"dnf\"].fillna(dnf_from_resultoverallScores)\n",
    "print(\"âœ… 'dnf' column updated by sequentially filling missing values from 'overallScores' THEN 'resultOverallScores'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30cca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸš€ Getting competitor details ðŸš€ ---\n"
     ]
    }
   ],
   "source": [
    "# Before filtering - extact key information from the 'competitors' column\n",
    "# player name column can contain team names.\n",
    "# competitors column keeps track of either the 1 player for a singles listing\n",
    "# or the multiple players for a team listing \n",
    "# some doubles matches may be leftover from payload filtering - need to filter out.\n",
    "# some doubles matches may be here inside team events - need to filter out.\n",
    "\n",
    "def extract_competitor_details(competitor_list):\n",
    "    \"\"\"\n",
    "    Extracts only the top-level competitor details (Name, ID, ORG) \n",
    "    for Home (H) and Away (A) competitors, ignoring the nested 'players' dict.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output dictionary  \n",
    "    data = {}\n",
    "    \n",
    "    # check for empty data incase \n",
    "    if not isinstance(competitor_list, list) or len(competitor_list) < 2:\n",
    "        return pd.Series(data)\n",
    "\n",
    "    try:\n",
    "        # use prefix pattern to determine home/away and build the keys for the output dict.\n",
    "        for comp in competitor_list:\n",
    "            comp_type = comp.get('competitorType')\n",
    "            \n",
    "            if comp_type == 'H':\n",
    "                prefix = 'home'\n",
    "            elif comp_type == 'A':\n",
    "                prefix = 'away'\n",
    "            else:\n",
    "                continue                \n",
    "           \n",
    "            \n",
    "            # get competitor id \n",
    "            data[f'{prefix}CompetitorId'] = comp.get('competitiorId', pd.NA)\n",
    "            \n",
    "            # get competitor name \n",
    "            data[f'{prefix}CompetitorName'] = comp.get('competitiorName', pd.NA)\n",
    "            \n",
    "            # get competitor country code \n",
    "            data[f'{prefix}CompetitorOrg'] = comp.get('competitiorOrg', pd.NA)\n",
    "\n",
    "            data[f'{prefix}Player(s)'] = [player.get('playerName', pd.NA) for player in comp.get('players', pd.NA)]\n",
    "\n",
    "            data[f'{prefix}PlayerGameScores'] = comp.get('scores', pd.NA)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e} | Data: {competitor_list}\")\n",
    "        pass\n",
    "\n",
    "    return pd.Series(data)\n",
    "\n",
    "#\n",
    "print(\"--- ðŸš€ Getting competitor details ðŸš€ ---\")\n",
    "\n",
    "# apply the function to the competitors column from the main df\n",
    "competitor_details_df = cleaned_matches_df['competitiors'].apply(extract_competitor_details)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_matches_df = pd.concat([cleaned_matches_df, competitor_details_df], axis=1)\n",
    "cleaned_matches_df.drop(columns=[\"competitiors\"],inplace=True, errors='ignore')\n",
    "\n",
    "print(\"âœ… Competitor details extracted and added to cleaned_matches_df and competitiors column dropped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2516764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_df before dropping para and age limit matches: 24469\n",
      "cleaned_df after dropping para and age limit matches: 24295\n"
     ]
    }
   ],
   "source": [
    "print(f\"cleaned_df before dropping para and age limit matches: {len(cleaned_matches_df)}\")\n",
    "age_limit_mask = cleaned_matches_df['subEventName'].str.contains(r\"U\\d{2}\", case=False, na=False)\n",
    "para_class_mask = cleaned_matches_df['subEventName'].str.contains(\"class\", case=False, na=False)\n",
    "age_para_filter = age_limit_mask | para_class_mask\n",
    "cleaned_matches_df = cleaned_matches_df[~age_para_filter].copy()\n",
    "\n",
    "\n",
    "print(f\"cleaned_df after dropping para and age limit matches: {len(cleaned_matches_df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388860e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_df before dropping names with teams_parent_data: 24295\n",
      "cleaned_df after dropping names with teams_parent_data: 23494\n"
     ]
    }
   ],
   "source": [
    "print(f\"cleaned_df before dropping names with teams_parent_data: {len(cleaned_matches_df)}\")\n",
    "team_parent_filter = cleaned_matches_df[\"teamParentData\"].notna()\n",
    "team_parent_df  = cleaned_matches_df[team_parent_filter].copy()\n",
    "cleaned_matches_df = cleaned_matches_df[~team_parent_filter ].copy()\n",
    "print(f\"cleaned_df after dropping names with teams_parent_data: {len(cleaned_matches_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_df before dropping names with numbers (teams): 23494\n",
      "cleaned_df after dropping names with numbers (teams): 23494\n"
     ]
    }
   ],
   "source": [
    "print(f\"cleaned_df before dropping names with numbers (teams): {len(cleaned_matches_df)}\")\n",
    "home_contains_digit = cleaned_matches_df[\"homeCompetitorName\"].str.contains(r\"[0-9]\", na=False)\n",
    "away_contains_digit = cleaned_matches_df[\"awayCompetitorName\"].str.contains(r\"[0-9]\", na=False)\n",
    "keep_filter = ~(home_contains_digit | away_contains_digit)\n",
    "cleaned_matches_df = cleaned_matches_df[keep_filter].copy()\n",
    "print(f\"cleaned_df after dropping names with numbers (teams): {len(cleaned_matches_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e14c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_df before dropping matches with multiple players (teams): 23494\n",
      "cleaned_df after dropping matches with multiple players (teams): 23494\n"
     ]
    }
   ],
   "source": [
    "print(f\"cleaned_df before dropping matches with multiple players (teams): {len(cleaned_matches_df)}\")\n",
    "home_multiple_players = cleaned_matches_df[\"homePlayer(s)\"].map(len) >1\n",
    "away_multiple_players = cleaned_matches_df[\"awayPlayer(s)\"].map(len) >1\n",
    "keep_filter = ~(home_multiple_players | away_multiple_players)\n",
    "remove_filter = (home_multiple_players | away_multiple_players)\n",
    "remove_df = cleaned_matches_df[remove_filter].copy()\n",
    "cleaned_matches_df = cleaned_matches_df[keep_filter].copy()\n",
    "print(f\"cleaned_df after dropping matches with multiple players (teams): {len(cleaned_matches_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32721206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a master list of 439 country/territory names and variants for fuzzy matching.\n",
      "cleaned_df before dropping matches with countries as 'player names' (teams): 23494\n",
      "cleaned_df after dropping matches with countries as 'player names' (teams): 23494\n"
     ]
    }
   ],
   "source": [
    "def build_country_name_list():\n",
    "    \"\"\"\n",
    "    Creates a comprehensive list of country names for fuzzy matching from pycountries\n",
    "    \"\"\"\n",
    "    country_names = set()\n",
    "    \n",
    "    #  Get ALL official names and common names from pycountry\n",
    "    for country in pycountry.countries:\n",
    "        # Standard Common Name\n",
    "        country_names.add(country.name)\n",
    "        # Official Full Name (often different)\n",
    "        if hasattr(country, 'official_name'):\n",
    "            country_names.add(country.official_name)\n",
    "        # Historical/Alternative Names (if the library provides them)\n",
    "        if hasattr(country, 'common_name'):\n",
    "             country_names.add(country.common_name)\n",
    "\n",
    "    # Add other possible options for sports teams across different tournaments and regions\n",
    "    # generated using Google Gemini - may be superfluous or be missing some possible options\n",
    "    \n",
    "    sports_variants = [\n",
    "        # China/Taiwan/HK\n",
    "        'Chinese Taipei', 'Taiwan', 'Hong Kong, China', 'Hong Kong','Macau, China', 'Macao'\n",
    "        # N/S Korea\n",
    "        'Republic of Korea', 'North Korea', 'South Korea', 'DPR Korea',\n",
    "        # Former Czech/Slovak\n",
    "        'Czechia', 'Czech Republic', 'Slovakia',\n",
    "        # Common English/French alternatives\n",
    "        'Ivory Coast', 'Cote d\\'Ivoire', 'Cape Verde', 'Cabo Verde',\n",
    "        # Common abbreviations that might appear unparsed\n",
    "        'DR Congo', 'ROC', 'PRC', 'USA', 'UK', 'UAE' \n",
    "    ]\n",
    "    \n",
    "    country_names.update(sports_variants)\n",
    "    \n",
    "    # Clean up the list (remove duplicates and empty/None entries)\n",
    "    final_list = [name.strip() for name in country_names if name and isinstance(name, str)]\n",
    "    \n",
    "    return final_list\n",
    "\n",
    "# Generate the master list\n",
    "list_of_countries = build_country_name_list()\n",
    "\n",
    "print(f\"Generated a master list of {len(list_of_countries)} country/territory names and variants for fuzzy matching.\")\n",
    "\n",
    "def fuzz_match_check(player_name, keywords_list, threshold):\n",
    "    \"\"\"\n",
    "    Checks if a player name has a high fuzzy match score against any\n",
    "    keyword in the list.\n",
    "    \"\"\"\n",
    "    # Safety check for empty/NA names\n",
    "    if pd.isna(player_name):\n",
    "        return False\n",
    "        \n",
    "    player_name_lower = str(player_name).lower()\n",
    "    \n",
    "    for keyword in keywords_list:\n",
    "        # We use partial_ratio to see if the keyword is 'contained'\n",
    "        # in the player name with high confidence.\n",
    "        score = fuzz.ratio(player_name_lower, keyword.lower())\n",
    "        \n",
    "        # If any keyword scores above the threshold, flag it as suspicious\n",
    "        if score >= threshold:\n",
    "            return True\n",
    "            \n",
    "    # If no keyword matched, it's a safe name\n",
    "    return False\n",
    "\n",
    "print(f\"cleaned_df before dropping matches with countries as 'player names' (teams): {len(cleaned_matches_df)}\")\n",
    "\n",
    "threshold = 90\n",
    "\n",
    "home_is_fuzzy = cleaned_matches_df['homeCompetitorName'].apply(fuzz_match_check,args=(list_of_countries,threshold))\n",
    "away_is_fuzzy = cleaned_matches_df['awayCompetitorName'].apply(fuzz_match_check,args=(list_of_countries,threshold))\n",
    "\n",
    "remove_check_filter = home_is_fuzzy | away_is_fuzzy\n",
    "remove_check_df = cleaned_matches_df[remove_check_filter].copy()\n",
    "cleaned_matches_df = cleaned_matches_df[~remove_check_filter]\n",
    "print(f\"cleaned_df after dropping matches with countries as 'player names' (teams): {len(cleaned_matches_df)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ed928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸš€ Getting Match Config deatils ðŸš€ ---\n",
      "âœ… Match config extracted and added to cleaned_matches_df,matchConfig column dropped.\n"
     ]
    }
   ],
   "source": [
    "# All teams matches should be removed by now \n",
    "\n",
    "def extract_format(config):\n",
    "    \"\"\"\n",
    "    Attempts to extract the best of format from the 'matchConfig' column\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    if not isinstance(config,dict):\n",
    "        return pd.Series(data)\n",
    "    try:\n",
    "        data['bestOf':] = config.get('bestOfXGames')\n",
    "        data['ttrReview'] = config.get('tTRReview')\n",
    "        return pd.Series(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e} | Data: {config}\")\n",
    "        pass\n",
    "    return pd.Series(data)\n",
    "#\n",
    "print(\"--- ðŸš€ Getting Match Config deatils ðŸš€ ---\")\n",
    "\n",
    "# apply the function to the competitors column from the main df\n",
    "match_config_df = cleaned_matches_df['matchConfig'].apply(extract_format)\n",
    "\n",
    "\n",
    "cleaned_matches_df = pd.concat([cleaned_matches_df, match_config_df], axis=1)\n",
    "cleaned_matches_df.drop(columns=[\"matchConfig\"],inplace=True, errors='ignore')\n",
    "\n",
    "print(\"âœ… Match config extracted and added to cleaned_matches_df,matchConfig column dropped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# After this filtering out - all matches left should be single player matches.\n",
    "# The following checks can bed done on top of this:\n",
    "# \"\"\"\n",
    "# # #### Check for players / teams with id length != 6 (6  appears to be the standard legnth but not for all players )###\n",
    "# # home_id_length_check = cleaned_matches_df[\"homeCompetitorId\"].astype(str).map(len) != 6\n",
    "# # away_id_length_check = cleaned_matches_df[\"awayCompetitorId\"].astype(str).map(len) != 6 \n",
    "# # id_check_filter = home_id_length_check | away_id_length_check\n",
    "# # id_check_df = cleaned_matches_df[id_check_filter].copy()\n",
    "# # away_names = cleaned_matches_df[\"awayCompetitorName\"].unique()\n",
    "# # home_names = cleaned_matches_df[\"homeCompetitorName\"].unique()\n",
    "# # all_names = away_names.tolist() + home_names.tolist()\n",
    "# # all_names = list(set(all_names))\n",
    "# # al;_names.to_csv(\"all_names.csv\", index=False)\n",
    "\n",
    "# ### Check for matches where homeCompetitorName !- homePlayer(s) or the same case for away (any artefacts from competitors filtering) ###\n",
    "# # home_check = cleaned_matches_df[\"homeCompetitorName\"].str.lower() != cleaned_matches_df[\"homePlayer(s)\"].str[0].str.lower()\n",
    "# # away_check = cleaned_matches_df[\"awayCompetitorName\"].str.lower() != cleaned_matches_df[\"awayPlayer(s)\"].str[0].str.lower()\n",
    "# # check_filter = home_check | away_check\n",
    "# # names_match_check_df = cleaned_matches_df[check_filter].copy()\n",
    "# # names_match_check_df.to_csv(\"names_match_check_df.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# ### This filter removes mismatches where one value is simply blank (due to different reporting)###\n",
    "# # blank_game_scores = cleaned_matches_df[\"gameScores\"].isna()\n",
    "# # blank_resultsGameScores = cleaned_matches_df[\"resultsGameScores\"].isna()\n",
    "# # both_blank_scores_df = cleaned_matches_df[blank_game_scores & blank_resultsGameScores].copy()\n",
    "# # One game has NO scores at all (2345\tTTEMSINGLES-----------R128001100----------\t) can look up manually \n",
    "# # This game appears to be a walkover in favour of David Powell (away) due a +ve covid test for Pavel Sirucek\n",
    "# # https://www.olympics.com.au/news/table-tennis-david-powell-fast-tracked-to-next-round/\n",
    "# #blank_scores_df = cleaned_matches_df[blank_game_scores & blank_resultsGameScores].copy()\n",
    "\n",
    "\n",
    "\n",
    "# ### Check for gameScores != resultsGameScores  (this should be 0 but not for team games ) ###\n",
    "# ### normalise gameScores and gameScores to remove blank 0-0 values ###\n",
    "\n",
    "# blank_game_scores = cleaned_matches_df[\"gameScores\"].isna()\n",
    "# blank_resultsGameScores = cleaned_matches_df[\"resultsGameScores\"].isna()\n",
    "# one_blank_score_filter = blank_game_scores | blank_resultsGameScores\n",
    "\n",
    "# game_scores_check = cleaned_matches_df[\"gameScores\"] != cleaned_matches_df[\"resultsGameScores\"]\n",
    "# normalised_gameScores = (\n",
    "#     cleaned_matches_df['gameScores']\n",
    "#     .astype(str)\n",
    "#     .str.replace(r'(,0-0)+$', '', regex=True) # Remove trailing 0-0 sequences\n",
    "#     .str.strip(',')                          # Remove any resulting trailing comma\n",
    "# )\n",
    "# normalised_resultGameScores = (\n",
    "#     cleaned_matches_df['resultsGameScores']\n",
    "#     .astype(str)\n",
    "#     .str.replace(r'(,0-0)+$', '', regex=True) # Remove trailing 0-0 sequences\n",
    "#     .str.strip(',')\n",
    "# )\n",
    "\n",
    "# score_mismatch_filter = (normalised_gameScores != normalised_resultGameScores)\n",
    "# non_dnf_filter= cleaned_matches_df[\"dnf\"].isna()\n",
    "# non_blank_mismatch_filter = score_mismatch_filter & ~one_blank_score_filter & non_dnf_filter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# games_mismatch_df = cleaned_matches_df[non_blank_mismatch_filter].copy()\n",
    "# games_mismatch_df[[\"eventId\",\"documentCode\",\"resultsGameScores\", \"gameScores\",\"overallScores\",\"resultOverallScores\",\"dnf\"]].to_csv(\"games_mismatch_df.csv\", index=False)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e07454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸŸ¢ Generating Name-to-ID Mapping for Review ðŸŸ¢---\n",
      "âœ… Mapped all names to their unique competitor IDs.\n",
      "Total unique competitor IDs found: 2808\n",
      "\n",
      "Discrepancy Report: Found 357 IDs with multiple names.\n",
      "You must inspect and choose a canonical name for these IDs:\n",
      "competitor_id\n",
      "100001                   [ANTHONY Amalraj, Amalraj ANTHONY]\n",
      "100032                 [ABDEL-AZIZ Farah, Farah ABDEL-AZIZ]\n",
      "100189                     [ALAWLAQI Ahmed, Ahmed ALAWLAQI]\n",
      "100439                           [SALEH Ahmed, Ahmed SALEH]\n",
      "100486                           [ALTO Gaston, Gaston ALTO]\n",
      "100621                     [Tiago APOLONIA, APOLONIA Tiago]\n",
      "100696                             [Omar ASSAR, ASSAR Omar]\n",
      "100868    [BALAZOVA Barbora, VARADY Barbora, Barbora BAL...\n",
      "101192                     [BOBOCICA Mihai, Mihai BOBOCICA]\n",
      "101480                       [CANTERO Jesus, Jesus CANTERO]\n",
      "Name: competitor_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now to assess the issues if the same player (sameID) being given multiple names \n",
    "print(\"--- ðŸŸ¢ Generating Name-to-ID Mapping for Review ðŸŸ¢---\")\n",
    "\n",
    "# 1. Combine the ID and Name columns into one DataFrame (Home and Away)\n",
    "home_map = cleaned_matches_df[['homeCompetitorId', 'homeCompetitorName']].rename(\n",
    "    columns={'homeCompetitorId': 'competitor_id', 'homeCompetitorName': 'competitor_name'}\n",
    ")\n",
    "away_map = cleaned_matches_df[['awayCompetitorId', 'awayCompetitorName']].rename(\n",
    "    columns={'awayCompetitorId': 'competitor_id', 'awayCompetitorName': 'competitor_name'}\n",
    ")\n",
    "\n",
    "# 2. Concatenate and drop duplicates to get a list of all unique ID-Name pairs\n",
    "all_id_name_pairs = pd.concat([home_map, away_map]).dropna().drop_duplicates()\n",
    "\n",
    "# 3. Group by ID and aggregate all associated names into a list\n",
    "id_to_names_map = all_id_name_pairs.groupby('competitor_id')['competitor_name'].unique()\n",
    "\n",
    "print(\"âœ… Mapped all names to their unique competitor IDs.\")\n",
    "print(f\"Total unique competitor IDs found: {len(id_to_names_map)}\")\n",
    "\n",
    "# 4. Filter for IDs that have MORE THAN ONE associated name (the problem cases)\n",
    "# This finds where the list of unique names for one ID is greater than length 1\n",
    "discrepancy_map = id_to_names_map[id_to_names_map.apply(len) > 1]\n",
    "\n",
    "print(f\"\\nDiscrepancy Report: Found {len(discrepancy_map)} IDs with multiple names.\")\n",
    "print(\"You must inspect and choose a canonical name for these IDs:\")\n",
    "print(discrepancy_map.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23494"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c80e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table_tennis_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
